{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sample\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import argparse\n",
    "import pickle \n",
    "import os\n",
    "from torch.autograd import Variable \n",
    "from torchvision import transforms \n",
    "from build_vocab import Vocabulary\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> a man is sitting at a table with a laptop . <end>\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "url = 'http...'\n",
    "sample_image_path = 'sample.jpg'\n",
    "\n",
    "urllib.request.urlretrieve(url, sample_image_path)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.image = sample_image_path\n",
    "        self.encoder_path = './models/encoder-5-3000.pkl'\n",
    "        self.decoder_path = './models/decoder-5-3000.pkl'\n",
    "        self.vocab_path = './data/vocab.pkl'\n",
    "        self.embed_size = 256\n",
    "        self.hidden_size = 512\n",
    "        self.num_layers = 1\n",
    "\n",
    "args = Args()\n",
    "\n",
    "sample.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
